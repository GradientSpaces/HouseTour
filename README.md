# ðŸ“š Master Thesis Code Repository: Touring Real Estates using Sparse Image Observationsâ€‹

<div style="display: flex; justify-content: center; align-items: center; height: 100vh;">
  <img src="./assets/recon_1.gif" style="width: 50%;">
</div>


## ðŸ“ Abstract
> This repository contains the implementation, data, and tools developed for my master's thesis, **Touring Real Estates using Sparse Image Observationsâ€‹**.  


## ðŸ“‚ Repository Structure

### Cosmos Tokenizer
The folder *cosmos_tokenizer* holds the code repository for the Cosmos Tokennizer + LLaMa model
```
â”œâ”€â”€ cosmos_tokenizer/  # Cosmos Tokennizer + LLaMa model files
â”œâ”€â”€ autodq.py          # Script for the AutoDQ LLaMa-based evaluation 
â”œâ”€â”€ eval_capt.py       # Script for the Dense Video Captioning evaluation
â”œâ”€â”€ eval_qa.py         # Script for the Open VQA evaluation
â”œâ”€â”€ eval.py            # Script for manual evaluation
â”œâ”€â”€ train_tf.py        # Script for T/F training
â”œâ”€â”€ train_q_and_a.py   # Script for Open VQA training
â””â”€â”€ train.py           # Script for Dense Video Captioning training 
```

### Data Acquisition
The folder *data_acquisition* holds the code repository for the Data Acquisition Pipeline
```
â”œâ”€â”€ singularity/                    # Cosmos Tokennizer + LLaMa model files
    â”œâ”€â”€ colmap_n_glomap.def         # Singularity recipe for COLMAP and GLOMAP installation on the cluster
    â””â”€â”€ pipe.def                    # Singularity recipe for the Data Acquisition environment on the cluster
â”œâ”€â”€ anyloc_retrieval.py             # 'AnyLoc' based Image Retrieval (experimental)
â”œâ”€â”€ blip_vqa.py                     # Removal of outdoor frames with BLIP2 Visual Question Answering
â”œâ”€â”€ build_vocab_tree.py             # Building a custom Vocabulary Tree for Image Retrieval (experimental)
â”œâ”€â”€ database_matches_to_txt.py      # Helper script to write the retrieved image pairs to a .txt file
â”œâ”€â”€ match_keyframes_mast3r_vocab.py # Finding two-view correspondences with Mast3r
â”œâ”€â”€ pipe_cluster.sh                 # Bash script for Data Acquisition 
â”œâ”€â”€ resize_keyframes.py             # Resizing the keyframes for further processing
â”œâ”€â”€ run.py                          # Generating a Dense Point Cloud after COLMAP mapping with Dust3r
â””â”€â”€ write_keypoints_h5.py           # Helper script to write the keypoints to an H5 file
```

### Datasets
The folder *datasets* holds the textual data used for the T/F, Open VQA and Dense Multi-Image Captioning tasks
```
â”œâ”€â”€ annotations_cleaned_v2.json     # The dataset used for Dense Multi-Image Captioning
â”œâ”€â”€ annotations_q_and_a.json        # The dataset used for Open VQA
â”œâ”€â”€ annotations_true_false.json     # The dataset used for T/F
â”œâ”€â”€ multi_image_pretrain_w8.json    # The dataset used for the Multi-Image pretraining (8 images) 
â””â”€â”€ multi_image_pretrain_w8.json    # The dataset used for the Multi-Image pretraining (16 images)
```

### QFormer + Sliding Window Video-QFormer & Multi-Image QFormer + LLaMa
The folder *housetour* holds the code repository for the QFormer + Sliding Window Video-QFormer & Multi-Image QFormer + LLaMa models
```
â”œâ”€â”€ grandtour/                  # QFormer + Sliding Window Video-QFormer & Multi-Image QFormer + LLaMa model files
â”œâ”€â”€ train_scripts/              
    â”œâ”€â”€ pretrain.py             # First Stage Pretraining Script for the Multi-Image QFormer
    â”œâ”€â”€ train_blip2_llama.py    # Second Stage LLM training Script for the Multi-Image QFormer
    â”œâ”€â”€ train_captioning.py     # Second Stage LLM training Script for the Multi-Image QFormer
    â”œâ”€â”€ train_dist_multi_n.py   # Multi-node parallel model training script
    â”œâ”€â”€ train_dist_one_n.py     # Single-node parallel model training script
    â”œâ”€â”€ train_full.py           # Training simulatenously on the T/F + Open VQA + Captioning datasets
    â”œâ”€â”€ train_q_and_a.py        # Training Script for Open VQA with QF+SWV-QF
    â”œâ”€â”€ train_true_or_false.py  # Training Script for T/F with QF+SWV-QF
    â””â”€â”€ train.py                # Training Script for Dense Multi-Image Captioning with QF+SWV-QF
â””â”€â”€ eval_scripts/               # Evaluation Scripts for the T/F, Open VQA and Dense Multi-Image Captioning tasks
```
