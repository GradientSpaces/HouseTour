model:
  arch: timechat
  model_type: pretrain_llama_v2
  freeze_vit: True
  freeze_qformer: True
  max_txt_len: 2048
  end_sym: "</s>"
  low_resource: False

  frozen_llama_proj: True
  frozen_video_Qformer: True

  # QFormer
  num_query_token: 32

  vit_model: "ckpt/eva-vit-g/eva_vit_g.pth"
  llama_model: "ckpt/Video-LLaMA-2-7B-Finetuned/llama-2-7b-chat-hf/"
  q_former_model: "ckpt/instruct-blip/instruct_blip_vicuna7b_trimmed.pth"
  ckpt: "ckpt/timechat/TimeChat-7b/timechat_7b.pth"

  fusion_head_layers: 2
  max_frame_pos: 96
  fusion_header_type: "seqTransf"

  use_grad_checkpoint: True
  lora: True
  lora_r: 16
  lora_alpha: 16
  lora_inference_mode: True
  qformer_text_input: False
  window_size: 4
  stride: 4

  context_size: 8
  image_size: [512, 288]
  
data:
  vis_root: "/scratch/users/atacelen/Reconstructions3D"
  ann_root: "/scratch/users/atacelen/Reconstructions3D/annotations.json"
  num_video_query_token: 32
  tokenizer_name: "ckpt/Video-LLaMA-2-7B-Finetuned/llama-2-7b-chat-hf/"
  data_type: video
  model_type: "llama_v2"
  sample_type: 'rand'
  max_txt_len: 512
  stride: 4

train:
  batch_size: 1
  num_workers: 4
  weight_decay: 0.05
  init_lr: 3e-5
  min_lr: 1e-5
  warmup_lr: 1e-6
  use_amp: True
  # iters_per_epoch: #TODO
  log_freq: 50
  accum_grad_iters: 8
  snapshot_path: "ckpt/snapshot.pth"

preprocess:
  vis_processor:
    eval:
      name: "custom_image_array_processor"
      image_size: [512, 288]
      # image_size: 224
      n_frms: 8


run:
  output_dir: "./results/"
  max_epochs: 3
  eval_only: False